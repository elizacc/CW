Машинное обучение может найти свое применение практически во всех сферах деятельности человека. Модели помогают обнаруживать мошеннические операции, предсказывать диагноз пациента и многое другое. Однако с развитием машинного обучения создаваемые модели становились все более сложными. Самые простые подходы, применявшиеся в начале данного направления, сейчас практически не используются, так как не выдерживают конкуренцию сложных структур, показывающих более высокое качество.

Однако простые модели обладают важным преимуществом -- результаты их работы относительно легко интерпретировать. Поэтому человек мог понять, адекватную ли модель он построил, можно ли доверять ее результатам. К сожалению, нельзя сказать то же самое про современные модели. Соответственно, появляется задача: создать методы интерпертации сложных моделей, которые на понятном человеку языке проинтерпретируют результаты.

Данная задача уже получила немалое количество решений. В данной работе мы рассмотрим некоторые из предлагаемых методов интерпретации моделей машинного обучения


%Во введении я хочу сказать про то что существует интерпретируемые и нет модели. Про то что нам хотелось бы интерпретировать и привести аргументы за (как минимум те 3 из презенташки). Наверное стоит объединить с блоком интерпретации, так как здесь особо больше нечего писать (если только много не получится), а воду лить не хочется

%1. Интерпретируемые и нет модели. Желательно показать примеры, почему не интерпретируются.
%2. Интерпретация нужна! Потому что...
%3. Плюсы интерпретации и небольшие минусы
%4. Что и как хотелось бы интерпретировать. Основы интерпретации -- какой она должна быть
%5. Кратко перечислить методы, сказать какие они бывают