Машинное обучение может найти свое применение практически во всех сферах деятельности человека. Модели помогают обнаруживать мошеннические операции, предсказывать диагноз пациента и многое другое. Однако с развитием машинного обучения создаваемые модели становятся все более сложными. Они показывают высокое качество, однако перестают быть понятными для человека.

Данный недостаток оказывается важным с разных точек зрения. В первую очередь, мы теряем возможность объяснить, как именно модель приняла то или иное решение. Мы не понимаем модель, а значит, не можем контролировать ее обучение напрямую -- лишь перестраивая ее структуру, надеясь изменить результат в нужную сторону.

% здесь недостатки отсутствия интерпретируемости

%Во введении я хочу сказать про то что существует интерпретируемые и нет модели. Про то что нам хотелось бы интерпретировать и привести аргументы за (как минимум те 3 из презенташки). Наверное стоит объединить с блоком интерпретации, так как здесь особо больше нечего писать (если только много не получится), а воду лить не хочется

%1. Интерпретируемые и нет модели. Желательно показать примеры, почему не интерпретируются.
%2. Интерпретация нужна! Потому что...
%3. Плюсы интерпретации и небольшие минусы
%4. Что и как хотелось бы интерпретировать. Основы интерпретации -- какой она должна быть
%5. Кратко перечислить методы, сказать какие они бывают