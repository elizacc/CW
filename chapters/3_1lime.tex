% авторы в статье вводят очень много обозначений. Нужно попробовать снизить их количество. Можно убрать: G
У нас есть модель $f(x): \re^d \rightarrow \re$ и объект $x \in \re^d$, предсказание для которого нужно интерпретировать. Мы хотим найти модель $g$ из класса интерпретируемых моделей $G$, чтобы получить из нее объяснение результата более сложной модели (например, посмотреть на веса признаков).

Сложность моделей обычно обратно зависит от ее интерпретируемости. Например, линейную модель с 2-3 предикторами гораздо проще интерпретировать, чем модель с 10 и более предикторами. Поэтому нам нужно не просто использовать более простую модель, но и преобразовать исходное пространство признаков: $x \rightarrow x'$. Стоит также помнить, что мы хотим получить интерпретацию на исходных предикторах. Поэтому нам не подходят методы снижения размерности, которые представляют признаки в уже неинтерпретируемом виде (PCA, UMAP и пр.). В данной задаче можно уменьшить количество признаков и преобразовать.
% верно ли про UMAP

Чтобы уменьшить количество признаков, мы можем случайно выбирать некоторые из них. Либо комбинировать их между собой, при этом обращая внимание на интерпретируемость новых признаков. Для каждого типа данных подобное преобразование может проходить по-разному: для изображений -- несколько пикселей могут объединяться в один суперпиксель, для текстов -- символы объединяться в токены (например, слова -- они хорошо интерпретируются).

Для преобразования признаков существует большое количество методов. Например, приведение непрерывных переменных к дискретному виду. Основная цель подобных преобразований: уменьшить множество значений признаков, после чего авторы алгоритма предлагают приводить предикторы к еще более упрощенному виду: использовать вместо признака дамми-переменную его наличия. Именно поэтому наша простая модель $g(x'):\{0,1\}^{d'} \rightarrow \re\,$ работает с интерпретируемым представлением предсказания $x' \in \{0,1\}^{d'}$, где обычно $d' << d$.
% что за бред, числовые переменные можно так и оставить, они же не мешают обучаться модели. или мешают
Дополнительно в задаче вводится мера сложности $\Omega(g)$ искомой модели как регуляризация. %Сложность модели может ограничиваться пользователем при регулировании гиперпараметров: глубина решающего дерева, количество моделей в ансамблях, количество слоев в нейронной сети и т.д.
% может быть здесь стоит писать все про интерпретируемые модели и не приводить такие примеры. Вообще не уверена что это нужна писать, здесь же мат часть

Чтобы определить окрестность рядом с $x$, внутри которой мы можем использовать простую модель, введем меру близости $\pi_x(z)$ между объектом $x$ и его соседом $z$. И наконец определим нашу функцию потерь, которую мы будем оптимизировать: $L(f, g, \pi_x)$ -- разница между моделями $f$ и $g$ в окрестности, заданной $\pi_x$. Тогда в целом задача алгоритма выглядит следующим образом:
\[
explanation(x) = \xi(x) = \underset{g \in G}{\argmin} (L(f, g, \pi_x) + \Omega(g))
\]

Одной из особенностей алгоритма является его независимость от модели, которую необходимо интерпретировать. Поэтому мы не можем приписывать модели $f$ никакие свойства. Вместо этого мы будем аппроксимировать ее, искусственно создавая объекты в окрестности $x'$, переводя их в исходное пространство признаков и получая для них предсказания из $f$.

Понятие окрестности носит абстрактный характер, поэтому чтобы учесть расстояние между объектами на практике, мы будем использовать меру близости $\pi_x(z)$ как веса: чем ближе объект к $x$, тем больший вклад он вносит в функцию потерь.

Гиперпараметры в задаче:\\[-8mm]
\begin{itemize}
	\item $G$ -- класс интерпретируемых моделей: линейные модели, решающие деревья и др.\\[-6mm]
	\item $d'$ -- количество признаков в новом пространстве
	\item $\pi_x(z)$ -- мера близости: например, ядра (гауссово, логистическое и др.)\\[-6mm]
	\item $D(x,z)$ -- расстояние между объектами, используемое при расчете меры близости: евклидова метрика, косинусное расстояние и др.\\[-6mm]
	\item $L$ -- функция потерь: $MSE$, $MAE$ и др.\\[-6mm]
\end{itemize}

% мне кажется процесс генерации новых объектов здесь не так важен
% у них еще есть тема с выбором примеров для объяснения модели -- пока что это не кажется важным
% непонятно что у них с простыми моделями -- они только линейные или нет
% есть гиперпараметр К

Результат: мы получаем алгоритм, который изучает работу более сложной модели и интерпретирует ее с некоторой погрешностью -- можно изучать влияние признаков на отдельные предсказания.
