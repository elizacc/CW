Обозначения:\\
$X = (x_1, \ldots, x_d)$ -- матрица признаков\\
$x_1, x_2$ -- векторы исследуемых признаков\\
$X_b = (x_3, \ldots, x_d)$ -- векторы остальных признаков\\
$a(x_1, \ldots, x_d)$ -- предсказания модели как функция от признаков

Нам нужно получить функцию зависимости предсказания от одного-двух признаков при зафиксированных остальных: $g(x_1, x_2) = a(x_1, x_2 | \, x_3, \ldots, x_d)$. Но если $x_1$ и/или $x_2$ зависимы с признаками из $X_b$, то возникает проблема. При изменении анализируемого признака меняется и зависимый с ним, который мы не рассматриваем -- мы не сможем рассмотреть чистый предельный эффект одного признака, на него всегда будет наложен эффект другого предиктора. Поэтому одной из предпосылок метода является независимость исследуемых признаков от остальных.

Но даже с предпосылкой о независимости признаков функция $g(x_1, x_2)$ не будет показывать точный результат, так как предельные эффекты предикторов разные для разных объектов выборки. Поскольку нашей задачей является посмотреть влияние выбранных признаков в целом, мы рассмотрим, как влияют анализируемые признаки на среднее предсказание. То есть найдем матожидание предсказания модели при фиксированных исследуемых признаках (как констант с точки зрения матожидания):

\[
\bar{g}(x_1, x_2) = \e(a(x_1, x_2, X_b) \, | X_b)
\]

Таким образом, мы получим функцию, которая показывает предельные эффекты признаков для среднего предсказания. Но чтобы найти матожидание, мы должны знать истинные распределения признаков. Поскольку нам недоступна данная информация, можно воспользоваться методом Монте-Карло, чтобы примерно оценить искомую функцию:

\[
\hat{g}(x_1, x_2) = \frac{1}{n} \isum a(x_1, x_2, X_b^{(i)}),
\]
где $X_b^{(i)}$ -- $i$ строка матрицы $X_b$
% не очень корректно, так как в функции векторы и скаляры

Результат: функция показывает, как исследуемые признаки в среднем влияют на результат работы модели. Мы можем построить ее график, чтобы более наглядно посмотреть на влияние предикторов на предсказание.

% добавить преимущества и недостатки

%Признаки могут иметь как непрерывное, так и дискретное распределение -- в том и другом случае мы сможем найти матожидание, при условии, что оно существует. Особо стоит отметить категориальные признаки



% почему бы просто эту функцию не находить
% способ дает меньшую точность там, где зависимость можно было достать из модели
% можно делать анимацию, если нельзя рассмотреть все сразу :)
% Должна быть предпосылка не о независимости случайных величин, а о том, что производная по исследуемому признаку не зависит от других величин -- возможно просто стоит написать, что обычно в моделях комбинации признаков не используются, а если и используются, то задаются извне пользователем. И если в этом способе используются какие-то комбинации даже этого признака с самим собой, и при этом они рассматриваются отдельно, то мне кажется этот метод будет бесполезен
% можно дополнить, что возможно стоит брать не матожидание, а предоставлять подставлять некоторые значения, потому что предельные эффекты все равно будут разные для всех