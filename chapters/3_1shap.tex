Метод SHAP несколько отличается от использования значений Шэпли напрямую для интерпретации вклада признаков. В нем

Мысли, которые нужно включить сюда:

+1. Как считается value

2. Есть value, есть вклад, есть прогноз -- надо понять как вклад связан с value

+3. Есть интерпретация -- можно вывести из предпосылок формулу value

4. Я не хочу выводить этот алгоритм через аддитивные модели -- я хочу попроще написать, а потом указать что она аддитивная и показать, что это

5. По возможности расписать как их находить и что с ними потом делать для интерпретации

6. Расписать разницу SHAP и Shaply values -- пока что не очень понятно

% привести к тому, что они показывают отклонение от среднего -- объясняют его