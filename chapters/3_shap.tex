SHAP (SHapley Additive exPlanations) -- метод, оценивающий вклад признаков в предсказания модели на основе значений Шэпли.

\subsubsection{Идея}
Предсказание модели формируется на основе признаков. Если мы хотим узнать влияние отдельного признака, мы можем построить предсказание модели с ним и без него и затем посмотреть, как меняется результат. % почему реально не убирать насовсем?
Но модель может быть слишком сложной, чтобы мы могли оценить влияние предиктора по одному объекту, регулируя один признак при фиксированных остальных. % а корректно ли занулять его, это ведь тоже какое-то значение
% помнить про то, что у shapley values есть свой раздел
Правильнее рассмотреть все возможные комбинации признаков: их разные значения, наличие/отсутствие, чтобы понять, как в каждом из перечисленных случаев добавление и исключение признака влияет на предсказание.

Рассматривая влияние в каждом конкретном случае, мы получаем огромное количество предельных эффектов, что тяжело интерпретируется. Поэтому можно рассмотреть, какой в среднем эффект оказывает включение признака в модель. Тогда мы получим средневзвешенную оценку вклада отдельного признака в предсказание, что позволит проинтерпретировать результат работы модели.
% Подумать, почему они сравнивают результат со средним кроме как кроме того что нужна всего одна модель и теряется точность

Однако для такого способа нужно обучить количество моделей, пропорциональное количеству всех комбинаций признаков -- которое растет экспоненциально с увеличением количества признаков. Либо оставлять пропущенные значения вместо исключенных признаков, что может плохо отразиться на качестве работы модели. Чтобы избежать этого, мы можем несколько видоизменить наше решение, не меняя цель. Вместо обучения дополнительной модели с меньшим количеством предикторов мы оценим ее предсказание, случайно изменяя исключенные признаки и усреднив результат.

% мб метод SHAP вносит еще какие-то идеи, но пока что так

\subsubsection{Значения Шэпли (Shapley values)}
Пусть $S$ -- множество не исключенных из модели признаков, в которое не входит исследуемый $i$-ый признак. Чтобы найти разницу предсказаний для признаков из $S$ и из $S \cup \{i\}$, куда входит $i$-ый признак, нам нужно обучить две модели, $f_S$ и $f_{S \cup \{i\}}$, соответственно. Тогда для объекта $x$ мы получим:
\[
f_{S \cup \{i\}}(x_{S \cup \{i\}}) - f_S(x_S),
\]

где $x_{S \cup \{i\}}$ -- объект $x$, у которого оставили только признаки из $S \cup \{i\}$, $x_S$ -- только признаки из $S$.

Как отмечалось ранее, значения данного выражения могут меняться при разных комбинациях признаков, поэтому мы усредним ее для всех возможных случаев. Считая, что $F$ -- множество всех признаков, получим итоговое выражение для $i$-го признака:
\[
\phi_i = \frac{1}{|F|} \sum\limits_{S \subseteq F \backslash \{i\}}
\begin{pmatrix}
|F| - 1 \\
|S|
\end{pmatrix}^{-1}
(f_{S \cup \{i\}}(x_{S \cup \{i\}}) - f_S(x_S)),
\]
где $|F|$ -- количество элементов в множестве $F$, $|S|$ -- в множестве $S$.

Коэффициент:
\[
\ds \begin{pmatrix}
|F| - 1 \\
|S|
\end{pmatrix} = \frac{(|F|-1)!}{|S|! \cdot (|F| - |S| - 1)!}
\]
равен количеству всех возможных комбинаций признаков без учета исследуемого. Поделив на него, а также на количество признаков получаем среднее значение вклада признака. % а зачем делить на колво признаков

Данный коэффициент также можно интерпретировать как вес комбинации при расчете среднего. Биномиальный коэффициент, равный количеству комбинаций, для одного или $|F|-1$ признаков меньше, чем для любого другого числа признаков. Соответственно, при делении на коэффициент мы получаем большее значение, который указывает на больший вес подобных комбинаций. Это имеет смысл, так как больше информации мы получаем, рассматривая влияние признаков по отдельности: либо оставляя только его, либо исключая все кроме него. С увеличением количества признаков в $S$ вес комбинации убывает.

Таким образом, мы получили величину, показывающую, какой в среднем вклад вносит конкретный признак в предсказание. Данное значение пришло из теории игр и носит название значение Шэпли (Shapley value). Они показывают, какой вклад внес в общий выигрыш отдельный игрок при кооперации. В нашей задаче мы рассматриваем предсказание модели как выигрыш, а признаки как игроков.